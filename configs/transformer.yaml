dataset:
  input_dim: 3
  single: False
  stats: dafa_ls
  mask_mode: none
  pixel_set: none
  pixel_wise: True
model:
  name: transformer
  in_channels: 3
  len_max_seq: 96
  d_word_vec: 32
  d_model: 32
  d_inner: 64
  n_layers: 3
  n_head: 8
  d_k: 8
  d_v: 8
  dropout: 0.2
  nclasses: 2
training:
  criterion: bce
  weight: False
  n_epochs: 2
  batch_size: 128
  num_workers: 8
  optimizer:
    lr: 0.0001
    weight_decay: 0.01
  scheduler:
    warmup: 100
    gamma: 0.1
    num_iter_per_step: [30000, 40000]
    min_lr: 0.00001